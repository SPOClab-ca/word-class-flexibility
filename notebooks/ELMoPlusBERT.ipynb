{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo and BERT Contextual Embeddings\n",
    "\n",
    "In this notebook, we use contextual embeddings from ELMo/BERT to study semantic change of conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.decomposition\n",
    "import random\n",
    "import scipy.stats\n",
    "\n",
    "import src.corpus\n",
    "import src.semantic_embedding\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UD_PATH = '../data/ud_all/ud-treebanks-v2.5/'\n",
    "#ud_files = src.corpus.group_treebanks_by_language(UD_PATH)\n",
    "#corpus = src.corpus.POSCorpus.create_from_ud(data_file_list=ud_files['English'])\n",
    "\n",
    "BNC_FILE = \"../data/wiki/processed_udpipe/en.pkl\"\n",
    "#BNC_FILE = \"../data/bnc/bnc.pkl\"\n",
    "corpus = src.corpus.POSCorpus.create_from_pickle(data_file_path=BNC_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embeddings on random part of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 1M words out of 4M to make it run faster\n",
    "SAMPLE_PROPORTION = 1\n",
    "random.seed(12345)\n",
    "random_indices = random.sample(range(len(corpus.sentences)), int(SAMPLE_PROPORTION * len(corpus.sentences)))\n",
    "\n",
    "sampled_sentences = []\n",
    "for ix in random_indices:\n",
    "  sampled_sentences.append(corpus.sentences[ix])\n",
    "  \n",
    "embedder = src.semantic_embedding.SemanticEmbedding(sampled_sentences)\n",
    "#embedder.init_bert(model_name='xlm-roberta-base', layer=11)\n",
    "embedder.init_elmo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embeddings of instances of a fixed lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_LEMMA = \"work\"\n",
    "#noun_embeddings, verb_embeddings, noun_indices, verb_indices = embedder.get_bert_embeddings_for_lemma(FIXED_LEMMA)\n",
    "noun_embeddings, verb_embeddings = embedder.get_elmo_embeddings_for_lemma(FIXED_LEMMA)\n",
    "print(\"Noun instances:\", noun_embeddings.shape[0])\n",
    "print(\"Verb instances:\", verb_embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply PCA and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "all_embeddings = pca.fit_transform(np.vstack([noun_embeddings, verb_embeddings]))\n",
    "all_embeddings_df = pd.DataFrame({'x0': all_embeddings[:,0], 'x1': all_embeddings[:,1]})\n",
    "all_embeddings_df['pos'] = ['Noun'] * len(noun_embeddings) + ['Verb'] * len(verb_embeddings)\n",
    "#all_embeddings_df['sentence_ix'] = noun_indices + verb_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(data=all_embeddings_df.sample(min(len(all_embeddings), 1000)),\n",
    "                       x='x0', y='x1', hue='pos', linewidth=0, s=20,\n",
    "                       palette=sns.color_palette(\"muted\", n_colors=2))\n",
    "handles, labels = plot.get_legend_handles_labels()\n",
    "plot.legend(handles=handles[1:], labels=labels[1:], loc=\"upper right\")\n",
    "plt.suptitle(\"Lemma: %s\" % FIXED_LEMMA, fontsize=14, y=0.95)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plot.axes.get_xaxis().set_ticks([])\n",
    "plot.axes.get_yaxis().set_ticks([])\n",
    "#plt.savefig('bert-work.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility to inspect what it's capturing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_printed = 0\n",
    "for _, row in all_embeddings_df.iterrows():\n",
    "  if row.x0 > 14: # <- Put whatever condition here\n",
    "    sent = sampled_sentences[row.sentence_ix]\n",
    "    print(\"POS=\" + row.pos + \";\", ' '.join([t['word'] for t in sent]))\n",
    "    num_printed += 1\n",
    "  if num_printed > 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity between noun and verb usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count_df = corpus.get_per_lemma_stats()\n",
    "\n",
    "# Filter: must have at least [x] noun and [x] verb usages\n",
    "lemma_count_df = lemma_count_df[(lemma_count_df['noun_count'] >= 30) & (lemma_count_df['verb_count'] >= 30)]\n",
    "lemma_count_df = lemma_count_df.sort_values('total_count', ascending=False)\n",
    "#lemma_count_df = lemma_count_df[~lemma_count_df.lemma.isin(['go', 'will', 'may'])]\n",
    "print('Remaining lemmas:', len(lemma_count_df))\n",
    "print('Noun lemmas:', len(lemma_count_df[lemma_count_df.majority_tag == 'NOUN']))\n",
    "print('Verb lemmas:', len(lemma_count_df[lemma_count_df.majority_tag == 'VERB']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count_df[['nv_cosine_similarity', 'n_variation', 'v_variation']] = \\\n",
    "  lemma_count_df.apply(lambda row: embedder.get_contextual_nv_similarity(row.lemma, method=\"elmo\"),\n",
    "                       axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count_df[['lemma', 'noun_count', 'verb_count', 'majority_tag', 'nv_cosine_similarity', 'n_variation', 'v_variation']] \\\n",
    "  .sort_values('nv_cosine_similarity').head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count_df[['lemma', 'noun_count', 'verb_count', 'majority_tag', 'nv_cosine_similarity', 'n_variation', 'v_variation']] \\\n",
    "  .sort_values('nv_cosine_similarity', ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in similarity when base is noun vs verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.distplot(lemma_count_df[lemma_count_df.majority_tag == 'NOUN'].nv_cosine_similarity, label='Base=N')\n",
    "plot = sns.distplot(lemma_count_df[lemma_count_df.majority_tag == 'VERB'].nv_cosine_similarity, label='Base=V')\n",
    "plt.legend()\n",
    "plot.set(title=\"Average Cosine Similarity between Noun/Verb Usage\",\n",
    "         xlabel=\"Cosine Similarity\", ylabel=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean cosine distance when Base=N:', 1-np.mean(lemma_count_df[lemma_count_df.majority_tag == 'NOUN'].nv_cosine_similarity))\n",
    "print('Mean cosine distance when Base=V:', 1-np.mean(lemma_count_df[lemma_count_df.majority_tag == 'VERB'].nv_cosine_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test of difference in mean\n",
    "scipy.stats.ttest_ind(lemma_count_df[lemma_count_df.majority_tag == 'NOUN'].nv_cosine_similarity,\n",
    "                      lemma_count_df[lemma_count_df.majority_tag == 'VERB'].nv_cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in variation between noun and verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean noun variation:', np.mean(lemma_count_df.n_variation))\n",
    "print('Mean verb variation:', np.mean(lemma_count_df.v_variation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t-test for difference\n",
    "scipy.stats.ttest_rel(lemma_count_df.n_variation, lemma_count_df.v_variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in variation between majority and minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_variation = np.where(lemma_count_df.majority_tag == 'NOUN', lemma_count_df.n_variation, lemma_count_df.v_variation)\n",
    "minority_variation = np.where(lemma_count_df.majority_tag == 'NOUN', lemma_count_df.v_variation, lemma_count_df.n_variation)\n",
    "plot = sns.distplot(majority_variation, label='Majority')\n",
    "plot = sns.distplot(minority_variation, label='Minority')\n",
    "plt.legend()\n",
    "plot.set(title=\"Semantic variation within majority and minority POS class\",\n",
    "         xlabel=\"Standard deviation\", ylabel=\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean majority variation:', np.mean(majority_variation))\n",
    "print('Mean minority variation:', np.mean(minority_variation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired t-test for difference\n",
    "scipy.stats.ttest_rel(majority_variation, minority_variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTurk correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df = pd.read_csv('../data/annotations/mturk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df = pd.merge(annotation_df, lemma_count_df, on='lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(annotation_df.mean_score, annotation_df.nv_cosine_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
