{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Embeddings\n",
    "\n",
    "Notebook to compare different embedding methods against MTurk labels to see what corresponds most with human judgements of semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1031 15:04:56.352830 140684008224512 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1031 15:04:56.443389 140684008224512 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import src.corpus\n",
    "import src.semantic_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNC_FILE = \"../data/bnc/bnc.pkl\"\n",
    "corpus = src.corpus.POSCorpus.create_from_bnc_pickled(data_file_path=BNC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>majority_tag</th>\n",
       "      <th>human_score1</th>\n",
       "      <th>human_score2</th>\n",
       "      <th>human_score3</th>\n",
       "      <th>human_score4</th>\n",
       "      <th>human_score5</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aim</td>\n",
       "      <td>137</td>\n",
       "      <td>98</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer</td>\n",
       "      <td>480</td>\n",
       "      <td>335</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt</td>\n",
       "      <td>302</td>\n",
       "      <td>214</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>care</td>\n",
       "      <td>403</td>\n",
       "      <td>249</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>control</td>\n",
       "      <td>519</td>\n",
       "      <td>179</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma  noun_count  verb_count majority_tag  human_score1  human_score2  \\\n",
       "0      aim         137          98         NOUN             2             2   \n",
       "1   answer         480         335         NOUN             2             2   \n",
       "2  attempt         302         214         NOUN             2             2   \n",
       "3     care         403         249         NOUN             2             2   \n",
       "4  control         519         179         NOUN             2             2   \n",
       "\n",
       "   human_score3  human_score4  human_score5  mean_score  \n",
       "0             2             2             2         2.0  \n",
       "1             2             2             2         2.0  \n",
       "2             2             2             2         2.0  \n",
       "3             2             2             2         2.0  \n",
       "4             2             2             2         2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_df = pd.read_csv('../data/annotations/myself_plus_mturk.csv')\n",
    "relevant_lemmas = annotation_df.lemma.tolist()\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sentences containing lemmas we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_relevant_lemmas = []\n",
    "for sentence in corpus.sentences:\n",
    "  for tok in sentence:\n",
    "    if tok['lemma'] in relevant_lemmas:\n",
    "      sentences_with_relevant_lemmas.append(sentence)\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder method: ELMo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embedder = src.semantic_embedding.SemanticEmbedding(sentences_with_relevant_lemmas)\n",
    "embedder.init_elmo(layer=0)\n",
    "annotation_df['nv_cosine_similarity'] = \\\n",
    "  annotation_df.apply(lambda row: embedder.get_elmo_nv_similarity(row.lemma), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder method: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = src.semantic_embedding.SemanticEmbedding(sentences_with_relevant_lemmas)\n",
    "embedder.init_bert()\n",
    "#annotation_df['nv_cosine_similarity'] = \\\n",
    "  #annotation_df.apply(lambda row: embedder.get_elmo_nv_similarity(row.lemma), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 213/76094 [00:28<1:13:15, 17.26it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8378346562385559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.get_contextual_nv_similarity('work', method='bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder method: GloVe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "embedder = src.semantic_embedding.SemanticEmbedding(sentences_with_relevant_lemmas)\n",
    "embedder.init_glove()\n",
    "annotation_df['nv_cosine_similarity'] = annotation_df.apply(\n",
    "  lambda row: embedder.get_glove_nv_similarity(row.lemma, context=0, include_self=True),\n",
    "  axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NV similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(annotation_df.mean_score, annotation_df.nv_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(annotation_df.mean_score, annotation_df.nv_cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
